# -*- coding: utf-8 -*-
"""heart_disease_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dgS7vQOALrqUnfMTXy1Zc0awgbJ7W3xa

**Heart disease prediction**

**Importing libraries**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn.datasets
from sklearn.model_selection import train_test_split

"""**Collecting the data**"""

df=pd.read_csv("/content/drive/MyDrive/Datasets/heart_statlog_cleveland_hungary_final.csv")

#the dataset comprises 1190 rows and 12 columns, with the last column serving as the target variable.
df.head()

df.shape

df.info()

df.describe()

df['target'].value_counts()

"""**Plotting**

Univariate analysis
"""

# Univariate analysis of 'age' column
plt.figure(figsize=(8, 6))
plt.hist(df['age'], bins=20, color='skyblue', edgecolor='black')
plt.title('Distribution of Age')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

# Counting occurrences of each sex
sex_counts = df['sex'].value_counts()

# Define labels for the pie chart
labels = ['Female', 'Male']

# Pie chart for distribution of 'sex' column
plt.figure(figsize=(6, 6))
plt.pie(sex_counts, labels=labels, colors=['lightcoral', 'lightskyblue'], autopct='%1.1f%%', startangle=90)
plt.title('Distribution of Sex')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle
plt.show()

#heart rate frequency
import pandas as pd
import matplotlib.pyplot as plt

# Define bins for heart rate
bins = range(60, 210, 10)

# Plot the histogram
plt.figure(figsize=(10, 6))
plt.hist(df['max heart rate'], bins=bins, color='skyblue', edgecolor='black', alpha=0.7)
plt.xlabel('Heart Rate (bpm)')
plt.ylabel('Frequency')
plt.title('Heart Rate Distribution')
plt.xticks(bins)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Bivariate analysis"""

# Scatter plot (Numerical vs Numerical with Target)
plt.figure(figsize=(8, 6))
sns.scatterplot(x='age', y='cholesterol', hue='target', data=df)
plt.title('Age vs Cholesterol with Target')
plt.xlabel('Age')
plt.ylabel('Cholesterol')
plt.grid(True)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(6, 4))
sns.barplot(x='sex', y='target', data=df, palette='Set2')
plt.title('Heart Disease by Sex')
plt.xlabel('Sex (0 = Female, 1 = Male)')
plt.ylabel('Probability of Heart Disease')
plt.xticks([0, 1], ['Female', 'Male'])
plt.show()

plt.figure(figsize=(6, 4))
sns.boxplot(x='sex', y='max heart rate', data=df, palette='Set2')
plt.title('Max Heart Rate by Sex')
plt.xlabel('Sex (0 = Female, 1 = Male)')
plt.ylabel('Max Heart Rate')
plt.xticks([0, 1], ['Female', 'Male'])
plt.show()

plt.figure(figsize=(8, 6))
sns.barplot(x='target', y='max heart rate', data=df, palette='Set2')
plt.title('Heart Rate Distribution by Heart Disease Status')
plt.xlabel('Target (0 = No Heart Disease, 1 = Heart Disease)')
plt.ylabel('Max Heart Rate')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(7,5))
sns.violinplot(x='chest pain type', y='max heart rate', data=df, palette='viridis')
plt.title('Max Heart Rate by Chest Pain Type')
plt.xlabel('Chest Pain Type')
plt.ylabel('Max Heart Rate')
plt.grid(True)
plt.show()

#age vs heart disease
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Create age bins and labels
bins = [30, 40, 50, 60, 70, 80]
labels = ['30-39', '40-49', '50-59', '60-69', '70-79']

# Bin the age data
df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=False)

# Group by age_group and calculate the mean target value
age_group_target = df.groupby('age_group')['target'].mean()

# Plot the data
plt.figure(figsize=(7,5))
age_group_target.plot(kind='bar', color='skyblue')
plt.xlabel('Age Group')
plt.ylabel('Proportion of Heart Disease')
plt.title('Proportion of Heart Disease by Age Group')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

#heat map of the dataset
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Create a correlation matrix
correlation_matrix = df.corr()

# Create heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Correlation Heatmap')
plt.show()

"""**Prediction model**

**Separating features and target**
"""

x=df.drop(columns='target', axis=1)     #considering all the columns except label column as features
y=df['target']                          #considering label column as the target

print(x)

print(y)

"""**Splitting training and testing data**"""

X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=2)

print(x.shape, X_train.shape, X_test.shape)

"""**Logistic Regression**"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Create and train the model
logistic_regression_model = LogisticRegression()
logistic_regression_model.fit(X_train, y_train)

# Make predictions
y_pred_lr = logistic_regression_model.predict(X_test)

# Evaluate the model
accuracy_lr = accuracy_score(y_test, y_pred_lr)
print("Logistic Regression Accuracy:", accuracy_lr)

"""**Multiple linear regression**"""

import numpy as np

from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score

# Flatten the sequences for linear regression
X_train_flatten = X_train.reshape(X_train.shape[0], -1)
X_test_flatten = X_test.reshape(X_test.shape[0], -1)

# Create and train the model
linear_regression_model = LinearRegression()
linear_regression_model.fit(X_train_flatten, y_train)

# Make predictions (round to 0 or 1)
y_pred_linear = np.round(linear_regression_model.predict(X_test_flatten))

# Convert to binary predictions
y_pred_linear[y_pred_linear < 0] = 0
y_pred_linear[y_pred_linear > 1] = 1

# Evaluate the model
accuracy_linear = accuracy_score(y_test, y_pred_linear)
print("Multiple Linear Regression Accuracy:", accuracy_linear)

"""**kNN**"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Flatten the sequences for KNN
X_train_flatten = X_train.reshape(X_train.shape[0], -1)
X_test_flatten = X_test.reshape(X_test.shape[0], -1)

# Create and train the model
knn_model = KNeighborsClassifier()
knn_model.fit(X_train_flatten, y_train)

# Make predictions
y_pred_knn = knn_model.predict(X_test_flatten)

# Evaluate the model
accuracy_knn = accuracy_score(y_test, y_pred_knn)
print("KNN Accuracy:", accuracy_knn)

"""**Random forest**"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Create and train the model
rf_model = RandomForestClassifier()
rf_model.fit(X_train_flatten, y_train)

# Make predictions
y_pred_rf = rf_model.predict(X_test_flatten)

# Evaluate the model
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print("Random Forest Accuracy:", accuracy_rf)

"""**SVM**"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Create and train the model
svm_model = SVC()
svm_model.fit(X_train_flatten, y_train)

# Make predictions
y_pred_svm = svm_model.predict(X_test_flatten)

# Evaluate the model
accuracy_svm = accuracy_score(y_test, y_pred_svm)
print("SVM Accuracy:", accuracy_svm)

"""**Gradient boosting**"""

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score

# Create and train the model
gb_model = GradientBoostingClassifier()
gb_model.fit(X_train_flatten, y_train)

# Make predictions
y_pred_gb = gb_model.predict(X_test_flatten)

# Evaluate the model
accuracy_gb = accuracy_score(y_test, y_pred_gb)
print("Gradient Boosting Accuracy:", accuracy_gb)

"""**Decision tree**"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Create and train the model
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train_flatten, y_train)

# Make predictions
y_pred_dt = dt_model.predict(X_test_flatten)

# Evaluate the model
accuracy_dt = accuracy_score(y_test, y_pred_dt)
print("Decision Tree Accuracy:", accuracy_dt)

"""**Comparison plot**"""

import matplotlib.pyplot as plt

# List of algorithms and their accuracies
algorithms = ['Logistic Regression', 'Multiple Linear Regression', 'KNN', 'Random Forest', 'SVM', 'Gradient Boosting', 'Decision Tree']
accuracies = [accuracy_lr, accuracy_linear, accuracy_knn, accuracy_rf, accuracy_svm, accuracy_gb, accuracy_dt]

# Plot the bar graph
plt.figure(figsize=(10, 6))
bars = plt.bar(algorithms, accuracies, color='skyblue')
plt.xlabel('Algorithms')
plt.ylabel('Accuracy')
plt.title('Accuracy Comparison of Heart Disease Prediction Algorithms')
plt.xticks(rotation=45, ha='right')
plt.ylim(0, 1)

# Add labels with percentages inside each bar
for bar, accuracy in zip(bars, accuracies):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width() / 2, height, f'{accuracy:.2%}', ha='center', va='bottom')

plt.tight_layout()
plt.show()

"""**Save random forest model and testing**

"""

from joblib import dump

# Save the model
dump(rf_model, '/content/drive/MyDrive/Datasets/random_forest_model.joblib')

from joblib import load

#load the saved model
model = load('/content/drive/MyDrive/Datasets/random_forest_model.joblib')

import numpy as np

# Define static input features (example)
input = np.array([[49, 0, 3, 160, 180, 0, 0, 156, 0, 1, 2]])

# Make predictions using the loaded model
prediction = model.predict(input)

# Map the prediction to 0 or 1
prediction_label = "Heart disease present" if prediction == 1 else "No heart disease"

# Print the prediction
print("Prediction:", prediction_label)